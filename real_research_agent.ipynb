{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d00d817b-4091-46ed-87ac-5a021cdc4260",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (0.1.8)\n",
      "Requirement already satisfied: tavily-python in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (0.3.4)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.2.7-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m0m\n",
      "\u001b[?25hCollecting langchain_anthropic\n",
      "  Downloading langchain_anthropic-0.1.20-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.15 in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from langgraph) (0.2.18)\n",
      "Requirement already satisfied: requests in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from tavily-python) (2.32.3)\n",
      "Requirement already satisfied: tiktoken>=0.5.1 in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from tavily-python) (0.7.0)\n",
      "Requirement already satisfied: httpx in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from tavily-python) (0.27.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from langchain-community) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4\n",
      "  Downloading SQLAlchemy-2.0.31-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp<4.0.0,>=3.8.3\n",
      "  Using cached aiohttp-3.9.5-cp311-cp311-macosx_11_0_arm64.whl (390 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Collecting langchain<0.3.0,>=0.2.7\n",
      "  Downloading langchain-0.2.7-py3-none-any.whl (983 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.6/983.6 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from langchain-community) (0.1.85)\n",
      "Collecting numpy<2,>=1\n",
      "  Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from langchain-community) (8.5.0)\n",
      "Collecting anthropic<1,>=0.28.0\n",
      "  Downloading anthropic-0.31.0-py3-none-any.whl (865 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.4/865.4 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from langchain_anthropic) (0.7.1)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.4.1-cp311-cp311-macosx_11_0_arm64.whl (53 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.5-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.9.4-cp311-cp311-macosx_11_0_arm64.whl (81 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from anthropic<1,>=0.28.0->langchain_anthropic) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from anthropic<1,>=0.28.0->langchain_anthropic) (1.9.0)\n",
      "Collecting jiter<1,>=0.4.0\n",
      "  Downloading jiter-0.5.0-cp311-cp311-macosx_11_0_arm64.whl (299 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.3/299.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from anthropic<1,>=0.28.0->langchain_anthropic) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from anthropic<1,>=0.28.0->langchain_anthropic) (1.3.1)\n",
      "Collecting tokenizers>=0.13.0\n",
      "  Using cached tokenizers-0.19.1-cp311-cp311-macosx_11_0_arm64.whl (2.4 MB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from anthropic<1,>=0.28.0->langchain_anthropic) (4.12.2)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Using cached marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: certifi in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from httpx->tavily-python) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from httpx->tavily-python) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from httpx->tavily-python) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from httpcore==1.*->httpx->tavily-python) (0.14.0)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0\n",
      "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.15->langgraph) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.15->langgraph) (24.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from requests->tavily-python) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from requests->tavily-python) (2.2.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from tiktoken>=0.5.1->tavily-python) (2024.5.15)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.15->langgraph) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->anthropic<1,>=0.28.0->langchain_anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->anthropic<1,>=0.28.0->langchain_anthropic) (2.20.1)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4\n",
      "  Downloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.6/402.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mypy-extensions>=0.3.0\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.42.1 in /Users/harrisonchase/.pyenv/versions/3.11.1/envs/data-enrichment/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.28.0->langchain_anthropic) (4.66.4)\n",
      "Installing collected packages: SQLAlchemy, numpy, mypy-extensions, multidict, marshmallow, jiter, fsspec, frozenlist, filelock, yarl, typing-inspect, huggingface-hub, aiosignal, tokenizers, dataclasses-json, aiohttp, anthropic, langchain-text-splitters, langchain_anthropic, langchain, langchain-community\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.0\n",
      "    Uninstalling numpy-2.0.0:\n",
      "      Successfully uninstalled numpy-2.0.0\n",
      "Successfully installed SQLAlchemy-2.0.31 aiohttp-3.9.5 aiosignal-1.3.1 anthropic-0.31.0 dataclasses-json-0.6.7 filelock-3.15.4 frozenlist-1.4.1 fsspec-2024.6.1 huggingface-hub-0.23.4 jiter-0.5.0 langchain-0.2.7 langchain-community-0.2.7 langchain-text-splitters-0.2.2 langchain_anthropic-0.1.20 marshmallow-3.21.3 multidict-6.0.5 mypy-extensions-1.0.0 numpy-1.26.4 tokenizers-0.19.1 typing-inspect-0.9.0 yarl-1.9.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph tavily-python langchain-community langchain_anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0668c64f-d9cb-43f7-8bad-95be50ee7fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f0f252f-5f51-47cb-97d6-f1ef27bace1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9a468a2b-bf7a-470c-bf1a-2aa052e96fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import Literal\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "import json\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from typing import TypedDict, Optional\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0429b66e-b7a1-4e9b-ac5d-652c35cd2118",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = TavilySearchResults(name=\"Search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "81d274a5-a460-44af-a3e4-072da0ec6636",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_model = ChatAnthropic(model_name=\"claude-3-5-sonnet-20240620\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8494f3f1-833b-458c-9e97-0f2e3243f3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Info(BaseModel):\n",
    "    headquarters: str = Field(description='City in which this company is headquartered, should be in the form \"San Francisco, USA\"')\n",
    "    number_employees: Optional[int] = Field(description=\"number of full time employees\")\n",
    "    investors: str = Field(description=\"Notable investors, should be a comma separated list\")\n",
    "    capital_raised: str = Field(description=\"amount of money raised, should be like: `None`, `10k`, `35m`, `1b` etc\")\n",
    "    ceo: str = Field(description=\"Name of CEO\")\n",
    "    ceo_college: str = Field(description=\"Where did the CEO go to college\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4871a442-493e-4e0c-be9e-160777cefa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_prompt = \"\"\"You are doing research on companies. You are trying to figure out this information:\n",
    "\n",
    "<info>\n",
    "{info}\n",
    "</info>\n",
    "\n",
    "\n",
    "You have access to the following tools:\n",
    "\n",
    "- `Search`: call a search tool and get back some results\n",
    "- `ScrapeWebsite`: scrape a website and get relevant notes about the company. This will update the notes above.\n",
    "- `Info`: call this when you are done and have gathered all the relevant info\n",
    "\n",
    "Here is the information you have about the company you are researching:\n",
    "\n",
    "Company Name: {company_name}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a1651b71-2a0f-4857-83c1-0e32407dbae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = main_prompt.format(info=Info.schema_json(), company_name=\"LangChain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7430c255-f3b4-434a-8dcc-c5f552922a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_prompt = \"\"\"You are doing research on companies. You are trying to figure out this information:\n",
    "\n",
    "<info>\n",
    "{info}\n",
    "</info>\n",
    "\n",
    "You just scraped the following website: {url}\n",
    "\n",
    "Based on the website content below, jot down some notes about the website.\n",
    "\n",
    "{content}\"\"\"\n",
    "def ScapeWebsite(url: str):\n",
    "    \"\"\"Used to scrape a website\"\"\"\n",
    "    loader = WebBaseLoader(url)\n",
    "    docs = loader.load()\n",
    "    website = docs[0].page_content\n",
    "    p = info_prompt.format(info=Info.schema_json(), url=url, content=website)\n",
    "    response = raw_model.invoke(p)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "100d9f6b-16c7-4903-a18c-2babaafd604f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, MessagesState, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "class GraphState(MessagesState):\n",
    "    company_name: str\n",
    "    info: Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b709423f-3170-4faa-b65f-17bddac6e12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Good(BaseModel):\n",
    "    reason: str\n",
    "    good: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c470b2d9-1944-4ec7-9e60-6521f42c7dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(state):\n",
    "    p = main_prompt.format(info=Info.schema_json(), company_name=state['company_name'])\n",
    "    messages = [{\"role\": \"human\", \"content\": p}] + state['messages']\n",
    "    return {\"messages\": model.invoke(messages)}\n",
    "\n",
    "\n",
    "def call_checker(state):\n",
    "    p = main_prompt.format(info=Info.schema_json(), company_name=state['company_name'])\n",
    "    messages = [{\"role\": \"human\", \"content\": p}] + state['messages'][:-1] # get rid of the last one\n",
    "    presumed_info = state['messages'][-1].tool_calls[0]['args']\n",
    "    p1 = f\"I am thinking of calling the info tool with the info below. Is this good? Give your reasoning as well. You can encourage the Assistant to look at specific URLs if that seems relevant, or do more searches.\\n\\n{presumed_info}\"\n",
    "    messages.append({\"role\": \"human\", \"content\": p1})\n",
    "    response = raw_model.with_structured_output(Good).invoke(messages)\n",
    "    if response.good:\n",
    "        try:\n",
    "            return {\"info\": Info(**state['messages'][-1].tool_calls[0]['args'])}\n",
    "        except Exception as e:\n",
    "            return {\"messages\": [ToolMessage(tool_call_id=state['messages'][-1].tool_calls[0]['id'], content=f\"Invalid response: {e}\")]}\n",
    "    else:\n",
    "        return {\"messages\": [ToolMessage(tool_call_id=state['messages'][-1].tool_calls[0]['id'], content=str(response), artifact=response)]}\n",
    "\n",
    "tool_node = ToolNode([search_tool, ScapeWebsite])\n",
    "\n",
    "def bad_agent(state):\n",
    "    return {\"messages\": [{\"content\": \"You must call one, and only one, tool!\", \"role\": \"user\"}]}\n",
    "\n",
    "def route_after_agent(state):\n",
    "    last_message = state['messages'][-1]\n",
    "    if len(last_message.tool_calls) != 1:\n",
    "        return \"bad_agent\"\n",
    "    elif last_message.tool_calls[0]['name'] == \"Info\":\n",
    "        return \"call_checker\"\n",
    "    else:\n",
    "        return \"tool_node\"\n",
    "\n",
    "\n",
    "def route_after_checker(state):\n",
    "    if 'info' in state:\n",
    "        return END\n",
    "    return \"call_model\"\n",
    "\n",
    "graph = StateGraph(GraphState)\n",
    "graph.add_node(call_model)\n",
    "graph.add_node(call_checker)\n",
    "graph.add_node(bad_agent)\n",
    "graph.add_node(\"tool_node\", tool_node)\n",
    "graph.set_entry_point(\"call_model\")\n",
    "graph.add_conditional_edges(\"call_model\", route_after_agent)\n",
    "graph.add_edge(\"tool_node\", \"call_model\")\n",
    "graph.add_conditional_edges(\"call_checker\", route_after_checker)\n",
    "graph.add_edge(\"bad_agent\", \"call_model\")\n",
    "graph = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1b0584c8-db39-46dd-a7b2-70cd0c241264",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content=[{'text': \"Certainly! I'll research LangChain and gather the required information using the available tools. Let's start with a search query to get some initial information about the company.\", 'type': 'text'}, {'id': 'toolu_016kiWe4nKZj3hLsMJ728KGD', 'input': {'query': 'LangChain company information headquarters investors funding CEO'}, 'name': 'Search', 'type': 'tool_use'}], response_metadata={'id': 'msg_01Vqj55jS2jjDzjfQnucqks6', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 974, 'output_tokens': 96}}, id='run-44dfc675-a09f-44dc-9cd2-c0c2874eda85-0', tool_calls=[{'name': 'Search', 'args': {'query': 'LangChain company information headquarters investors funding CEO'}, 'id': 'toolu_016kiWe4nKZj3hLsMJ728KGD', 'type': 'tool_call'}], usage_metadata={'input_tokens': 974, 'output_tokens': 96, 'total_tokens': 1070}),\n",
       "  ToolMessage(content='[{\"url\": \"https://pitchbook.com/profiles/company/522935-92\", \"content\": \"Information on valuation, funding, cap tables, investors, and executives for LangChain. Use the PitchBook Platform to explore the full profile.\"}, {\"url\": \"https://www.crunchbase.com/organization/langchain\", \"content\": \"Headquarters Regions San Francisco Bay Area, West Coast, Western US. Founded Date 2022. Founders Ankush Gola, Harrison Chase. Operating Status Active. Last Funding Type Series A. Legal Name LangChain, Inc. Company Type For Profit. LangChain is a language model application development library that develops a language model framework to power ...\"}, {\"url\": \"https://www.crunchbase.com/organization/langchain/company_financials\", \"content\": \"LangChain has raised a total of. $35M. in funding over 2 rounds. Their latest funding was raised on Feb 15, 2024 from a Series A round. LangChain is funded by 2 investors. Sequoia Capital and Benchmark are the most recent investors. Unlock for free.\"}, {\"url\": \"https://blog.langchain.dev/announcing-our-10m-seed-round-led-by-benchmark/\", \"content\": \"Some of our more recent releases are focused on addressing these problems:\\\\nWe will continue to add features to LangChain and provide other offerings that will:\\\\nWe\\\\u2019re incredibly excited to see what will be built and to do more to support you. You might also like\\\\nMaking Data Ingestion Production Ready: a LangChain-Powered Airbyte Destination\\\\nConversational Retrieval Agents\\\\nLangChain Expression Language\\\\nGoodbye CVEs, Hello `langchain_experimental`\\\\n[Week of 7/24] LangChain Release Notes\\\\nAutomating Web Research\\\\n\\\\u00a9 LangChain Blog 2023 - Powered by Ghost We believe that the two main value props it provides are:\\\\nComponents\\\\nLangChain offers a modular set of abstractions and components that provide everything developers need to build applications using language models. Some highlights:\\\\nFuture Plans\\\\nAs mentioned earlier, we believe that language models are unlocking new types of high-value applications, and it is still non-trivial to create and maintain these applications \\\\u2014 particularly in production settings. Thank you for everything so far, and let\\\\u2019s build some cool stuff \\\\ud83d\\\\ude42\\\\nTags\\\\nJoin our newsletter\\\\nUpdates from the LangChain team and community\\\\nProcessing your application...\\\\n\"}, {\"url\": \"https://www.forbes.com/companies/langchain/\", \"content\": \"LangChain. Founded in late 2022, LangChain was an instant hit in Silicon Valley for its software that enables anyone to build apps powered by large language models like GPT-4 in as little as two ...\"}]', name='Search', id='0303d610-0fe2-4b2c-aa61-6d5c78c85644', tool_call_id='toolu_016kiWe4nKZj3hLsMJ728KGD'),\n",
       "  AIMessage(content=[{'text': \"Based on the search results, I've gathered some information about LangChain. However, we still need more details to complete the required information. Let's use the information we have and search for the missing pieces.\\n\\n1. Headquarters: San Francisco Bay Area (we need to be more specific)\\n2. Investors: Sequoia Capital, Benchmark\\n3. Capital Raised: $35M (total funding)\\n4. CEO: Not explicitly mentioned, but founders are Ankush Gola and Harrison Chase\\n5. CEO College: Missing information\\n\\nLet's search for more specific information about the headquarters and the CEO.\", 'type': 'text'}, {'id': 'toolu_01EHQpKwvF7a4boDutDQW18S', 'input': {'query': 'LangChain headquarters specific location San Francisco'}, 'name': 'Search', 'type': 'tool_use'}], response_metadata={'id': 'msg_013r1c8gpRvG57EZEtrhe4XD', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 1774, 'output_tokens': 194}}, id='run-762242aa-beed-4d1c-8238-20b66a0af099-0', tool_calls=[{'name': 'Search', 'args': {'query': 'LangChain headquarters specific location San Francisco'}, 'id': 'toolu_01EHQpKwvF7a4boDutDQW18S', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1774, 'output_tokens': 194, 'total_tokens': 1968}),\n",
       "  ToolMessage(content='[{\"url\": \"https://www.crunchbase.com/organization/langchain\", \"content\": \"Headquarters Regions San Francisco Bay Area, West Coast, Western US. Founded Date 2022. Founders Ankush Gola, Harrison Chase. Operating Status Active. Last Funding Type Series A. Legal Name LangChain, Inc. Company Type For Profit. LangChain is a language model application development library that develops a language model framework to power ...\"}, {\"url\": \"https://pitchbook.com/profiles/company/522935-92\", \"content\": \"LangChain Comparisons Description Primary Industry HQ Location Employees Total Raised Post Valuation Last Financing Details Developer of a language model framework designed to power applications that integrate with other sources of data and int Software Development Applications San Francisco, CA 43 As of 2024 0000 00000 0000-00-00 00000000000 ...\"}, {\"url\": \"https://craft.co/langchain\", \"content\": \"LangChain has 1 employees at their 1 location and $35 m in total funding,. See insights on LangChain including office locations, competitors, revenue, financials, executives, subsidiaries and more at Craft.\"}, {\"url\": \"https://www.dnb.com/business-directory/company-profiles.langchain_inc.5994911e750322fb7facae08fcb89d60.html\", \"content\": \"Find company research, competitor information, contact details & financial data for Langchain Inc. of San Francisco, CA. Get the latest business insights from Dun & Bradstreet.\"}, {\"url\": \"https://www.forbes.com/companies/langchain/\", \"content\": \"LangChain. Founded in late 2022, LangChain was an instant hit in Silicon Valley for its software that enables anyone to build apps powered by large language models like GPT-4 in as little as two ...\"}]', name='Search', id='4ae1e25b-0456-4d0a-9223-ec9ca66e6ce0', tool_call_id='toolu_01EHQpKwvF7a4boDutDQW18S'),\n",
       "  AIMessage(content=[{'text': \"Now we have more specific information about the headquarters. Let's search for information about the CEO and their education.\", 'type': 'text'}, {'id': 'toolu_01CJ9Xtyf5Uq2UNrhm93f4hb', 'input': {'query': 'LangChain CEO Harrison Chase education college'}, 'name': 'Search', 'type': 'tool_use'}], response_metadata={'id': 'msg_01TcGhAqrsv33tyBBvNsUxaJ', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 2423, 'output_tokens': 83}}, id='run-ccef9217-cc9d-4e7a-af15-fafff7dd7290-0', tool_calls=[{'name': 'Search', 'args': {'query': 'LangChain CEO Harrison Chase education college'}, 'id': 'toolu_01CJ9Xtyf5Uq2UNrhm93f4hb', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2423, 'output_tokens': 83, 'total_tokens': 2506}),\n",
       "  ToolMessage(content='[{\"url\": \"https://www.linkedin.com/in/harrison-chase-961287118\", \"content\": \"{sports, machine learning, software engineering, statistics} \\\\u00b7 Experience: LangChain \\\\u00b7 Education: Harvard University \\\\u00b7 Location: San Francisco \\\\u00b7 500+ connections on LinkedIn. View Harrison ...\"}, {\"url\": \"https://tedai-sanfrancisco.ted.com/speakers-1/harrison-chase-/co-founder-and-ceo,-langchain/\", \"content\": \"Harrison Chase, a Harvard graduate in statistics and computer science, co-founded LangChain to streamline the development of Language Model applications with open-source Python/Typescript packages. Chase\\'s experience includes heading the Machine Learning team at Robust Intelligence, focusing on the testing and validation of machine learning models, and leading the entity linking team at Kensho ...\"}, {\"url\": \"https://www.forbes.com/profile/harrison-chase/\", \"content\": \"Cofounder, LangChain. Harrison Chase only cofounded LangChain in late 2022, but the company caught instant attention for enabling anyone to build apps powered by large language models like GPT-4 ...\"}, {\"url\": \"https://en.wikipedia.org/wiki/LangChain\", \"content\": \"In October 2023 LangChain introduced LangServe, a deployment tool designed to facilitate the transition from LCEL (LangChain Expression Language) prototypes to production-ready applications.[5]\\\\nIntegrations[edit]\\\\nAs of March 2023, LangChain included integrations with systems including Amazon, Google, and Microsoft Azure cloud storage; API wrappers for news, movie information, and weather; Bash for summarization, syntax and semantics checking, and execution of shell scripts; multiple web scraping subsystems and templates; few-shot learning prompt generation support; finding and summarizing \\\\\"todo\\\\\" tasks in code; Google Drive documents, spreadsheets, and presentations summarization, extraction, and creation; Google Search and Microsoft Bing web search; OpenAI, Anthropic, and Hugging Face language models; iFixit repair guides and wikis search and summarization; MapReduce for question answering, combining documents, and question generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and pymupdf for PDF file text extraction and manipulation; Python and JavaScript code generation, analysis, and debugging; Milvus vector database[6] to store and retrieve vector embeddings; Weaviate vector database[7] to cache embedding and data objects; Redis cache database storage; Python RequestsWrapper and other methods for API requests; SQL and NoSQL databases including JSON support; Streamlit, including for logging; text mapping for k-nearest neighbors search; time zone conversion and calendar operations; tracing and recording stack symbols in threaded and asynchronous subprocess runs; and the Wolfram Alpha website and SDK.[8] As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.[2]\\\\nHistory[edit]\\\\nLangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. In April 2023, LangChain had incorporated and the new startup raised over $20 million in funding at a valuation of at least $200 million from venture firm Sequoia Capital, a week after announcing a $10 million seed investment from Benchmark.[3][4]\\\\n The project quickly garnered popularity, with improvements from hundreds of contributors on GitHub, trending discussions on Twitter, lively activity on the project\\'s Discord server, many YouTube tutorials, and meetups in San Francisco and London. As of April 2023, it can read from more than 50 document types and data sources.[9]\\\\nReferences[edit]\\\\nExternal links[edit]\"}, {\"url\": \"https://www.latent.space/p/langchain\", \"content\": \"And so you can do a lot of things like reflection and kind of like making sure that you\\'re on the right track and really put more safeguards and thinking about these agents as opposed to relying on like chas and interface, like the bot we have that\\'s on GitHub answering questions on the issues, I think probably gives better answers than the bots that we have that are on chat on the website. [00:50:32]\\\\nHarrison: And then between kind of like allowing for, I think one helpful thing that we did in terms of like distinguishing between basically the base interfaces and then more complex stuff is part of the separation around the docs is there\\'s like the components piece, which has the model IO, the retrieval, the agents, the callbacks, things like that. And then like, I know a lot of people are doing this, but like a personal assistant for like managing like email calendar, basic stuff, which I think is, I think that\\'s like a fantastic application for these like agent like things, because if you think about personal assistants today, you usually interact, I don\\'t have one, but I\\'m told you interact with them over email. Show Notes\\\\nLangChain\\\\nLangChain\\\\u2019s Berkshire Hathaway Homepage\\\\nAbstractions tweet\\\\nLangSmith\\\\nLangSmith Cookbooks repo\\\\nLangChain Retrieval blog\\\\nEvaluating CSV Question/Answering blog and YouTube\\\\nMultiOn Partner blog\\\\nHarvard Sports Analytics Collective\\\\nEvaluating RAG Webinar\\\\nawesome-langchain:\\\\nLLM Math Chain\\\\nSelf-Ask\\\\nLangChain Hub UI\\\\n\\\\u201cLangChain is Pointless\\\\u201d\\\\nHarrison\\\\u2019s links\\\\nsports - estimating player compatibility in the NBA\\\\nearly interest in prompt injections\\\\nGitHub\\\\nTwitter\\\\nTimestamps\\\\n[00:00:00] Introduction\\\\n[00:00:48] Harrison\\'s background and how sports led him into ML\\\\n[00:04:54] Memory (for long running chats, whether a simple Buffer, Knowledge Graph, Summary, or Vector Store)\\\\nUse-Cases: compositions of Components\\\\nChains: combining a PromptTemplate, LLM Model and optional OutputParser\\\\nwith Router, Sequential, and Transform Chains for advanced usecases\\\\nsavable, sharable schemas that can be loaded from LangChainHub\\\\nAgents: a chain that has access to a suite of tools, of nondeterministic8 length because the LLM is used as a reasoning engine to determine which actions to take and in which order.\"}]', name='Search', id='a24b0a09-8bd4-4f4e-a427-18440a3790c9', tool_call_id='toolu_01CJ9Xtyf5Uq2UNrhm93f4hb'),\n",
       "  AIMessage(content=[{'text': \"Great! Now we have gathered all the necessary information to complete the required fields. Let's use the `Info` function to provide the collected data:\", 'type': 'text'}, {'id': 'toolu_016v5ZcTkpwr4Q9jrRdnkBBT', 'input': {'headquarters': 'San Francisco, USA', 'number_employees': 43, 'investors': 'Sequoia Capital, Benchmark', 'capital_raised': '35m'}, 'name': 'Info', 'type': 'tool_use'}], response_metadata={'id': 'msg_01QRNU7e2dfh1eSbNvSxMXaP', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 4038, 'output_tokens': 148}}, id='run-2fce38b2-af17-427b-9904-e7edf538fa74-0', tool_calls=[{'name': 'Info', 'args': {'headquarters': 'San Francisco, USA', 'number_employees': 43, 'investors': 'Sequoia Capital, Benchmark', 'capital_raised': '35m'}, 'id': 'toolu_016v5ZcTkpwr4Q9jrRdnkBBT', 'type': 'tool_call'}], usage_metadata={'input_tokens': 4038, 'output_tokens': 148, 'total_tokens': 4186}),\n",
       "  ToolMessage(content='reason=\"The information provided is incomplete according to the required fields specified in the info schema. We are missing the \\'ceo\\' and \\'ceo_college\\' fields, which are required. Additionally, we should verify the number of employees and ensure we have the most up-to-date information for all fields.\" good=False', id='2ddb04db-1511-47f1-808e-a1c0d577f2af', tool_call_id='toolu_016v5ZcTkpwr4Q9jrRdnkBBT', artifact=Good(reason=\"The information provided is incomplete according to the required fields specified in the info schema. We are missing the 'ceo' and 'ceo_college' fields, which are required. Additionally, we should verify the number of employees and ensure we have the most up-to-date information for all fields.\", good=False)),\n",
       "  AIMessage(content=[{'text': \"I apologize for the oversight. You're right that we're missing some required information. Let me provide the missing details and ensure we have the most up-to-date information:\\n\\n1. CEO: Harrison Chase (co-founder and CEO)\\n2. CEO College: Harvard University\\n\\nLet's update the Info call with all the required fields:\", 'type': 'text'}, {'id': 'toolu_01NHNzrsjV2V1fkATTCx7he2', 'input': {'headquarters': 'San Francisco, USA', 'number_employees': 43, 'investors': 'Sequoia Capital, Benchmark', 'capital_raised': '35m', 'ceo': 'Harrison Chase', 'ceo_college': 'Harvard University'}, 'name': 'Info', 'type': 'tool_use'}], response_metadata={'id': 'msg_01HJQZ3DdGyTNFBqAJrgrLTU', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 4266, 'output_tokens': 230}}, id='run-c2ba53ee-3140-463d-8532-836b5f2b9190-0', tool_calls=[{'name': 'Info', 'args': {'headquarters': 'San Francisco, USA', 'number_employees': 43, 'investors': 'Sequoia Capital, Benchmark', 'capital_raised': '35m', 'ceo': 'Harrison Chase', 'ceo_college': 'Harvard University'}, 'id': 'toolu_01NHNzrsjV2V1fkATTCx7he2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 4266, 'output_tokens': 230, 'total_tokens': 4496})],\n",
       " 'company_name': 'LangChain',\n",
       " 'info': Info(headquarters='San Francisco, USA', number_employees=43, investors='Sequoia Capital, Benchmark', capital_raised='35m', ceo='Harrison Chase', ceo_college='Harvard University')}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"company_name\": \"LangChain\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae6292d-32f8-4ed1-b7b0-5ecba3eeffbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
